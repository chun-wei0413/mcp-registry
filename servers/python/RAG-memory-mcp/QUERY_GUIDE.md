# ChromaDB æŸ¥è©¢æŒ‡å—

## å¿«é€Ÿé–‹å§‹

### 1ï¸âƒ£ é€šé Python ç›´æ¥æŸ¥è©¢

æœ€æ¨è–¦çš„æ–¹å¼ - ç›´æ¥ä½¿ç”¨ VectorStoreServiceï¼š

```python
from services.vector_store_service import VectorStoreService

# åˆå§‹åŒ–
vs = VectorStoreService(
    db_path="./chroma_db",
    collection_name="ai_documentation"  # â­ ä¸»è¦æ–‡æª”ç´¢å¼•
)

# åŸºæœ¬æœå°‹
results = vs.search_knowledge(
    query="aggregate",
    top_k=5
)

# è™•ç†çµæœ
for result in results:
    print(f"ä¸»é¡Œ: {result['topic']}")
    print(f"ç›¸ä¼¼åº¦: {result['similarity']:.4f}")
    print(f"å…§å®¹: {result['content'][:200]}...")
    print(f"ä¾†æº: {result.get('file_path', 'N/A')}")

    # ç²å–ä»£ç¢¼å¡Š
    if result.get('code_blocks'):
        for code in result['code_blocks']:
            print(f"\nä»£ç¢¼ ({code['language']}):")
            print(code['code'])
    print("\n" + "="*80)
```

**è¼¸å‡ºç¤ºä¾‹ï¼š**
```
ä¸»é¡Œ: core-index
ç›¸ä¼¼åº¦: 0.5360
å…§å®¹: ## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€éº¼æ˜¯ Aggregateï¼Ÿ
- **ä¸€è‡´æ€§é‚Šç•Œ**ï¼šä¿è­‰å…§éƒ¨ç‹€æ…‹çš„ä¸€è‡´æ€§
- **äº‹å‹™é‚Šç•Œ**ï¼šæ‰€æœ‰è®Šæ›´åœ¨å–®ä¸€äº‹å‹™ä¸­å®Œæˆ
- **èšåˆæ ¹**ï¼šå¤–éƒ¨åªèƒ½é€šéèšåˆæ ¹è¨ªå•èšåˆå…§éƒ¨
...
ä¾†æº: tech-stacks/java-ca-ezddd-spring/examples/aggregate/README.md
```

---

### 2ï¸âƒ£ æŒ‰å„ªå…ˆç´šæœå°‹

åªæœå°‹ Critical å’Œ High å„ªå…ˆç´šçš„æ–‡æª”ï¼š

```python
from services.vector_store_service import VectorStoreService

vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

# ç²å–æ‰€æœ‰æ–‡æª”
all_docs = vs.collection.get()

# éæ¿¾å„ªå…ˆç´š
high_priority_docs = [
    (all_docs['ids'][i], all_docs['documents'][i], all_docs['metadatas'][i])
    for i in range(len(all_docs['ids']))
    if all_docs['metadatas'][i].get('priority') in ['critical', 'high']
]

print(f"é«˜å„ªå…ˆç´šæ–‡æª”: {len(high_priority_docs)}")

# åœ¨é«˜å„ªå…ˆç´šæ–‡æª”ä¸­æœå°‹
query_embedding = vs.model.encode("aggregate").tolist()
results = vs.collection.query(
    query_embeddings=[query_embedding],
    n_results=5,
    where={"priority": {"$in": ["critical", "high"]}}
)
```

---

### 3ï¸âƒ£ æŒ‰åˆ†é¡æœå°‹

åªæœå°‹æŸå€‹åˆ†é¡çš„æ–‡æª”ï¼š

```python
vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

# æœå°‹æç¤ºèªï¼ˆpromptsï¼‰åˆ†é¡
results = vs.search_knowledge(
    query="å¦‚ä½•å¯«æ¸¬è©¦?",
    top_k=5
)

# éæ¿¾çµæœ
prompt_results = [
    r for r in results
    if 'prompts' in r['topic'].lower()
]

for result in prompt_results:
    print(f"{result['topic']}: {result['content'][:150]}...")
```

---

### 4ï¸âƒ£ æŒ‰ä¸»é¡Œæœå°‹

åˆ©ç”¨å…ƒæ•¸æ“šä¸­çš„ topics æ¬„ä½ï¼š

```python
vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

# æœå°‹åŒ…å«ç‰¹å®šä¸»é¡Œçš„æ–‡æª”
results = vs.search_knowledge("testing", top_k=5)

# éæ¿¾åŒ…å« "testing" ä¸»é¡Œçš„çµæœ
testing_results = [
    r for r in results
    if 'testing' in r.get('topic', '').lower()
]

for result in testing_results:
    print(f"ä¸»é¡Œ: {result['topic']}")
    print(f"å…§å®¹: {result['content'][:100]}...")
```

---

### 5ï¸âƒ£ ç²å–ç‰¹å®šé¡åˆ¥çš„æ‰€æœ‰æ–‡æª”

```python
vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

# ç²å–æ‰€æœ‰æ–‡æª”
all_docs = vs.collection.get()

# æŒ‰åˆ†é¡åˆ†çµ„
from collections import defaultdict
by_category = defaultdict(list)

for i, doc_id in enumerate(all_docs['ids']):
    category = all_docs['metadatas'][i].get('category', 'unknown')
    by_category[category].append({
        'id': doc_id,
        'content': all_docs['documents'][i][:100],
        'source': all_docs['metadatas'][i].get('source_file')
    })

# é¡¯ç¤ºèšåˆæ–‡æª”
print(f"Aggregate ç›¸é—œæ–‡æª”:")
for doc in by_category.get('examples', []):
    if 'aggregate' in doc['source'].lower():
        print(f"  - {doc['source']}")
```

---

## Collections é¸æ“‡

### ä½•æ™‚ä½¿ç”¨ `ai_documentation`

âœ… **æ¨è–¦ç”¨æ–¼ï¼š**
- æœå°‹ .ai ç›®éŒ„çš„æ–‡æª”
- ç²å–ç·¨ç¢¼æ¨™æº–å’Œæœ€ä½³å¯¦è¸
- æŸ¥æ‰¾æç¤ºèªå’Œç¯„ä¾‹
- ç²å–å®Œæ•´çš„ä»£ç¢¼ç‰‡æ®µ

```python
vs = VectorStoreService(
    db_path="./chroma_db",
    collection_name="ai_documentation"  # â­ 1,116 chunks
)
```

### ä½•æ™‚ä½¿ç”¨ `mcp_knowledge_base`

âœ… **æ¨è–¦ç”¨æ–¼ï¼š**
- æŸ¥è©¢é …ç›®æ‘˜è¦å’Œç¸½çµ
- ç²å–å·¥ä½œé€²åº¦è¨˜éŒ„
- å­˜å„²å€‹äººç­†è¨˜å’Œæ±ºç­–
- ç°¡å–®çš„çŸ¥è­˜ç®¡ç†

```python
vs = VectorStoreService(
    db_path="./chroma_db",
    collection_name="mcp_knowledge_base"  # 2 documentsï¼ˆå¯æ“´å±•ï¼‰
)
```

---

## å¯¦ç”¨ç¤ºä¾‹

### ç¯„ä¾‹ 1ï¼šæŸ¥è©¢ Aggregate çš„å®Œæ•´ä¿¡æ¯

```python
from services.vector_store_service import VectorStoreService

vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

print("=" * 80)
print("æŸ¥è©¢: Aggregate å¯¦ä½œ")
print("=" * 80)

results = vs.search_knowledge("aggregate", top_k=5)

for i, result in enumerate(results, 1):
    print(f"\n{i}. ã€{result['topic']}ã€‘")
    print(f"   ç›¸ä¼¼åº¦: {result['similarity']:.4f}")
    print(f"   å„ªå…ˆç´š: {result.get('priority', 'N/A')}")
    print(f"   ä¾†æº: {result.get('file_path', 'N/A')}")
    print(f"   å…§å®¹é è¦½:")
    print(f"   {result['content'][:300]}...\n")

    if result.get('code_blocks'):
        print(f"   âœ… åŒ…å« {len(result['code_blocks'])} å€‹ä»£ç¢¼å¡Š")
        for code in result['code_blocks'][:2]:  # åªé¡¯ç¤ºå‰ 2 å€‹
            print(f"\n   ã€{code['language']} ä»£ç¢¼ã€‘")
            print(f"   {code['code'][:200]}...\n")
```

**è¼¸å‡ºï¼š**
```
================================================================================
æŸ¥è©¢: Aggregate å¯¦ä½œ
================================================================================

1. ã€core-indexã€‘
   ç›¸ä¼¼åº¦: 0.5360
   å„ªå…ˆç´š: critical
   ä¾†æº: tech-stacks/java-ca-ezddd-spring/examples/aggregate/README.md
   å…§å®¹é è¦½:
   ## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

   ### ä»€éº¼æ˜¯ Aggregateï¼Ÿ
   - **ä¸€è‡´æ€§é‚Šç•Œ**ï¼šä¿è­‰å…§éƒ¨ç‹€æ…‹çš„ä¸€è‡´æ€§...

   âœ… åŒ…å« 5 å€‹ä»£ç¢¼å¡Š
```

---

### ç¯„ä¾‹ 2ï¼šæœå°‹æ¸¬è©¦ç›¸é—œçš„æ–‡æª”

```python
from services.vector_store_service import VectorStoreService

vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

# æœå°‹æ¸¬è©¦ç›¸é—œå…§å®¹
results = vs.search_knowledge("å¦‚ä½•ç·¨å¯«å–®å…ƒæ¸¬è©¦", top_k=10)

# æŒ‰å„ªå…ˆç´šæ’åº
high_priority = sorted(
    [r for r in results if r.get('priority') == 'critical'],
    key=lambda x: x['similarity'],
    reverse=True
)

print("ğŸ¯ High Priority Testing Results:\n")
for result in high_priority[:3]:
    print(f"âœ… {result['topic']}")
    print(f"   {result['content'][:150]}...\n")
```

---

### ç¯„ä¾‹ 3ï¼šç²å–æ‰€æœ‰ä»£ç¢¼æ¨™æº–

```python
from services.vector_store_service import VectorStoreService

vs = VectorStoreService(db_path="./chroma_db", collection_name="ai_documentation")

# æœå°‹ç·¨ç¢¼æ¨™æº–
results = vs.search_knowledge("ç·¨ç¢¼è¦ç¯„", top_k=20)

# éæ¿¾ coding-standards åˆ†é¡
standards = [
    r for r in results
    if 'coding-standards' in r['topic'].lower()
]

print(f"æ‰¾åˆ° {len(standards)} å€‹ç·¨ç¢¼æ¨™æº–æ–‡æª”\n")

for result in standards[:5]:
    print(f"ğŸ“‹ {result['topic']}")
    section = result.get('section_title', 'N/A')
    print(f"   Section: {section}")
    print(f"   Preview: {result['content'][:100]}...\n")
```

---

## ChromaDB ç›´æ¥ API æŸ¥è©¢

å¦‚æœä½ æƒ³å®Œå…¨æŒæ§æŸ¥è©¢é‚è¼¯ï¼š

```python
import chromadb
from sentence_transformers import SentenceTransformer

# é€£æ¥åˆ° ChromaDB
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.get_collection(name="ai_documentation")

# åŠ è¼‰æ¨¡å‹
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# æŸ¥è©¢
query = "aggregate"
query_embedding = model.encode(query).tolist()

results = collection.query(
    query_embeddings=[query_embedding],
    n_results=5,
    include=["documents", "metadatas", "distances"]
)

# è™•ç†çµæœ
for i, doc_id in enumerate(results['ids'][0]):
    doc = results['documents'][0][i]
    meta = results['metadatas'][0][i]
    distance = results['distances'][0][i]

    print(f"{i+1}. Distance: {distance:.4f}")
    print(f"   Category: {meta['category']}")
    print(f"   Content: {doc[:100]}...")
    print()
```

---

## å¸¸è¦‹æŸ¥è©¢æ¨¡å¼

### æŸ¥è©¢æ¨¡å¼ 1ï¼šå®Œå…¨ç›¸ä¼¼æœå°‹

```python
vs.search_knowledge("aggregate", top_k=5)
```

### æŸ¥è©¢æ¨¡å¼ 2ï¼šå¸¶æ¢ä»¶çš„æœå°‹

```python
# ç›´æ¥æŸ¥è©¢ + çµæœéæ¿¾
results = vs.search_knowledge("aggregate", top_k=10)
filtered = [r for r in results if r['priority'] == 'critical']
```

### æŸ¥è©¢æ¨¡å¼ 3ï¼šå¤šæ¢ä»¶éæ¿¾

```python
results = vs.search_knowledge("æ¸¬è©¦", top_k=20)
filtered = [
    r for r in results
    if r.get('priority') in ['critical', 'high']
    and 'junit' in r['topic'].lower()
]
```

### æŸ¥è©¢æ¨¡å¼ 4ï¼šåˆ†é¡æª¢ç´¢

```python
# ç›´æ¥åœ¨ä½ç´š API ä¸Šç”¨ where éæ¿¾
results = vs.collection.query(
    query_embeddings=[query_embedding],
    n_results=5,
    where={"category": "prompts-subagent"}
)
```

---

## æ€§èƒ½è²¼å£«

| æ“ä½œ | æ™‚é–“ | èªªæ˜ |
|------|------|------|
| å–®æ¬¡æœå°‹ | <100ms | å¿«é€ŸéŸ¿æ‡‰ |
| ç²å–å…¨éƒ¨æ–‡æª” | ~500ms | 1,116 å€‹æ–‡æª” |
| éæ¿¾åˆ†é¡ | <50ms | å…§å­˜æ“ä½œ |
| æ¨¡å‹è¼‰å…¥ | 2-3s | é¦–æ¬¡åˆå§‹åŒ– |

**å„ªåŒ–å»ºè­°ï¼š**
1. âœ… è¤‡ç”¨ VectorStoreService å¯¦ä¾‹ï¼ˆä¸è¦æ¯æ¬¡éƒ½åˆå§‹åŒ–ï¼‰
2. âœ… ä½¿ç”¨ `where` éæ¿¾æ¸›å°‘çµæœé›†
3. âœ… æ‰¹é‡æŸ¥è©¢æ™‚ä½¿ç”¨åˆ—è¡¨æ¨å°å¼
4. âœ… é™åˆ¶ `top_k` çš„å¤§å°ï¼ˆé€šå¸¸ 5-10 å·²è¶³å¤ ï¼‰

---

## æ•…éšœæ’é™¤

### å•é¡Œ 1ï¼šæ²’æœ‰æœå°‹çµæœ

```python
# âœ… æª¢æŸ¥é›†åˆæ˜¯å¦æœ‰æ•¸æ“š
print(vs.collection.count())  # æ‡‰è©²æ˜¯ 1116

# âœ… è©¦è©¦æ›´é€šç”¨çš„æŸ¥è©¢
results = vs.search_knowledge("code", top_k=5)

# âœ… æª¢æŸ¥æŸ¥è©¢èªè¨€
results = vs.search_knowledge("æ¸¬è©¦", top_k=5)  # æ”¯æ´ä¸­æ–‡
```

### å•é¡Œ 2ï¼šæ¨¡å‹åŠ è¼‰å¤±æ•—

```python
# âœ… ç¢ºä¿æ¨¡å‹å·²ä¸‹è¼‰
import sentence_transformers
model = sentence_transformers.SentenceTransformer(
    "paraphrase-multilingual-MiniLM-L12-v2"
)  # æœƒè‡ªå‹•ä¸‹è¼‰ (~80MB)
```

### å•é¡Œ 3ï¼šç›¸ä¼¼åº¦åˆ†æ•¸å¾ˆä½

```python
# âœ… ä½åˆ†æ•¸ï¼ˆ>0.5ï¼‰ä»è¡¨ç¤ºç›¸é—œ
# âœ… å˜—è©¦èª¿æ•´ top_k çœ‹æ›´å¤šçµæœ
results = vs.search_knowledge(query, top_k=10)

# âœ… æŸ¥çœ‹è·é›¢è€Œéç›¸ä¼¼åº¦
for r in results:
    print(f"Distance: {r['similarity']}")  # <0.5 æ˜¯å¥½çµæœ
```

---

## æ¨è–¦æµç¨‹

```
é–‹å§‹
  â†“
é¸æ“‡ Collection
  â”œâ”€ ai_documentationï¼ˆæ¨è–¦ï¼‰ â†’ é …ç›®æ–‡æª”æœå°‹
  â””â”€ mcp_knowledge_base â†’ çŸ¥è­˜åº«æŸ¥è©¢
  â†“
åˆå§‹åŒ– VectorStoreService
  â†“
åŸ·è¡Œæœå°‹
  vs.search_knowledge(query, top_k=5)
  â†“
è™•ç†çµæœ
  â”œâ”€ é¡¯ç¤ºå…§å®¹
  â”œâ”€ ç²å–ä»£ç¢¼å¡Š
  â””â”€ éæ¿¾/æ’åº
  â†“
å®Œæˆ
```

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025-11-24
**æ¨è–¦ Collectionï¼š** `ai_documentation`ï¼ˆ1,116 chunksï¼‰
**é»˜èªæ¨¡å‹ï¼š** paraphrase-multilingual-MiniLM-L12-v2
